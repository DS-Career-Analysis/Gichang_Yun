{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b2f2e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen, HTTPError\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "keyword = ['데이터 사이언티스트', '데이터 애널리스트', '데이터 엔지니어']\n",
    "page = 1\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "Title = []\n",
    "Company = []\n",
    "Link = []\n",
    "Location = []\n",
    "label = []\n",
    "StackTool = []\n",
    "Requirement = []\n",
    "Preference = []\n",
    "\n",
    "# url, 공고 이름, 기업명, 기업 주소를 찾는 크롤링코드\n",
    "for search_keyword in keyword:\n",
    "    driver.get(f'https://www.saramin.co.kr/zf_user/search/recruit?search_area=main&search_done=y&search_optional_item=n&searchType=recently&searchword={search_keyword}&recruitPage={page}&recruitSort=relation&recruitPageCount=100&inner_com_type=&company_cd=0%2C1%2C2%2C3%2C4%2C5%2C6%2C7%2C9%2C10&show_applied=&quick_apply=&except_read=&ai_head_hunting=')\n",
    "    ct_result = driver.find_element(By.XPATH, '//*[@id=\"recruit_info\"]/div[1]/span').text\n",
    "    total_result = re.sub(r'[^0-9]', '', ct_result)\n",
    "    page_ct = int(int(total_result)/100)\n",
    "\n",
    "    for pages in range(1, page_ct+2):\n",
    "        driver.get(f'https://www.saramin.co.kr/zf_user/search/recruit?search_area=main&search_done=y&search_optional_item=n&searchType=recently&searchword={search_keyword}&recruitPage={pages}&recruitSort=relation&recruitPageCount=100&inner_com_type=&company_cd=0%2C1%2C2%2C3%2C4%2C5%2C6%2C7%2C9%2C10&show_applied=&quick_apply=&except_read=&ai_head_hunting=')\n",
    "        driver.implicitly_wait(time_to_wait=60)\n",
    "\n",
    "        div_title = driver.find_elements(By.CLASS_NAME, \"job_tit\")\n",
    "        div_company = driver.find_elements(By.CLASS_NAME, \"corp_name\")\n",
    "        div_stacktool = driver.find_elements(By.CLASS_NAME, \"job_sector\")\n",
    "        div_location = driver.find_elements(By.CLASS_NAME, \"job_condition\")\n",
    "        \n",
    "        try:\n",
    "            for item in div_title:\n",
    "                tmp_url = item.find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "                Link.append(tmp_url)\n",
    "                \n",
    "        except Exception as e:\n",
    "            Link.append(\"None\")\n",
    "            print(\"Link is not exist\")\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            for item in div_title:\n",
    "                tmp_title = item.find_element(By.TAG_NAME, \"a\").text\n",
    "                Title.append(tmp_title)\n",
    "                \n",
    "        except Exception as e:\n",
    "            Title.append(\"None\")\n",
    "            print(\"Title is not exist\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for item in div_company:\n",
    "                tmp_cn = item.find_element(By.TAG_NAME, \"a\").text\n",
    "                Company.append(tmp_cn)\n",
    "                label.append(search_keyword)\n",
    "        except Exception as e:\n",
    "            Company.append(\"None\")\n",
    "            print(\"Company is not exist\")\n",
    "            position_name.append(search_keyword)\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            for item in div_stacktool:\n",
    "                tmp_stacktool = []\n",
    "                tmp_stack = item.find_elements(By.TAG_NAME, \"a\")\n",
    "                for i in tmp_stack:\n",
    "                    stack = i.text\n",
    "                    tmp_stacktool.append(stack)\n",
    "                StackTool.append(tmp_stacktool)\n",
    "                \n",
    "        except Exception as e:\n",
    "            StackTool.append(\"None\")\n",
    "            print(\"StackTool is not exist\")\n",
    "            pass\n",
    "            \n",
    "\n",
    "        try:\n",
    "            for loc in div_location:\n",
    "                tmp_location = loc.find_element(By.TAG_NAME, \"span\").text\n",
    "                Location.append(tmp_location)\n",
    "                \n",
    "        except Exception as e:\n",
    "            Location.append(\"None\")\n",
    "            print(\"Location is not exist\")\n",
    "            pass\n",
    "            \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "50147c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "m_df = pd.DataFrame({\n",
    "    'Title': Title,\n",
    "    'Company': Company,\n",
    "    'StackTool' : StackTool,\n",
    "    'Link': Link,\n",
    "    'Location': Location,\n",
    "    'label': label\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6121b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = m_df.Title.value_counts()\n",
    "vc = m_df[m_df.Title.isin(value_counts[m_df.Title.value_counts() > 1].index)]\n",
    "for i in vc.index:\n",
    "    m_df.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6bed8817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████▌        | 2256/2540 [2:25:40<18:20,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver\")\n",
    "Content = []\n",
    "\n",
    "with tqdm(total=len(m_df['Link'])) as pbar:  # Initialize tqdm progress bar\n",
    "    for url in m_df['Link']:\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(time_to_wait=60)\n",
    "        \n",
    "        try:\n",
    "            driver.switch_to.frame(\"iframe_content_0\")\n",
    "            contents = driver.find_element(By.CLASS_NAME, \"user_content\").text\n",
    "            Content.append(contents)\n",
    "            \n",
    "        except Exception as e:\n",
    "            Content.append(\"None\")\n",
    "            pass\n",
    "        \n",
    "        pbar.update(1)  # Update progress bar\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df['Content']=Content\n",
    "\n",
    "m_df.to_csv(\"saramin.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
